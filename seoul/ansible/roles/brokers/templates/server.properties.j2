broker.id=83
process.roles=broker

inter.broker.listener.name=BROKER
advertised.listeners=INTERNAL://{{docker_compose_public_ip}}:29092,BROKER://{{docker_compose_public_ip}}:39092,CLIENT://{{docker_compose_public_ip}}:49092
listeners=INTERNAL://:9090,BROKER://:9091,CLIENT://:9092
listener.security.protocol.map=CONTROLLER:PLAINTEXT,INTERNAL:SASL_PLAINTEXT,BROKER:SASL_PLAINTEXT,CLIENT:SASL_PLAINTEXT

controller.listener.names=CONTROLLER
controller.quorum.voters=101@{{cp1_controller1_a_private_ip}}:9093,102@{{cp1_controller2_a_private_ip}}:9093,103@{{cp1_controller3_a_private_ip}}:9093

metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter
confluent.metrics.reporter.bootstrap.servers={{docker_compose_public_ip}}:29092,{{docker_compose_public_ip}}:39092,{{docker_compose_public_ip}}:49092
confluent.metrics.reporter.security.protocol=SASL_PLAINTEXT
confluent.metrics.reporter.sasl.mechanism=SCRAM-SHA-512
confluent.metrics.reporter.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="admin-secret";

auto.create.topics.enable=true
default.replication.factor=3

log.cleanup.policy=delete
log.dirs=/appData/data/kafka
log.retention.check.interval.ms=300000
log.retention.hours=72
log.segment.bytes=1073741824

message.max.bytes=1048588
metadata.max.retention.ms=604800000
min.insync.replicas=2
num.io.threads=8
num.network.threads=3
num.partitions=3
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3

replica.lag.time.max.ms=30000
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
socket.send.buffer.bytes=102400
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3
unclean.leader.election.enable=false

confluent.cluster.link.enable=true
confluent.balancer.enable=false
confluent.tier.enable=false
kafka.rest.enable=false

confluent.license.topic=_confluent-command
confluent.license.topic.replication.factor=3

sasl.enabled.mechanisms=OAUTHBEARER,SCRAM-SHA-512
sasl.mechanism.inter.broker.protocol=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="admin-secret";

listener.name.internal.sasl.enabled.mechanisms=OAUTHBEARER
listener.name.internal.oauthbearer.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required publicKeyPath="/var/ssl/private/public.pem";
listener.name.internal.oauthbearer.sasl.login.callback.handler.class=io.confluent.kafka.server.plugins.auth.token.TokenBearerServerLoginCallbackHandler
listener.name.internal.oauthbearer.sasl.server.callback.handler.class=io.confluent.kafka.server.plugins.auth.token.TokenBearerValidatorCallbackHandler
listener.name.broker.sasl.enabled.mechanisms=SCRAM-SHA-512
listener.name.broker.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="admin-secret";
listener.name.client.sasl.enabled.mechanisms=SCRAM-SHA-512
listener.name.client.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="admin-secret";

authorizer.class.name=io.confluent.kafka.security.authorizer.ConfluentServerAuthorizer
confluent.authorizer.access.rule.providers=CONFLUENT
confluent.metadata.server.enable=true
super.users=User:admin;User:ANONYMOUS

#ldap.group.name.attribute=cn
#ldap.group.object.class=groupOfNames
#ldap.group.member.attribute=member
#ldap.group.member.attribute.pattern=uid=(.*),ou=People,dc=timegate,dc=com
#ldap.group.search.base=ou=Group,dc=timegate,dc=com
#ldap.group.search.filter=(|(cn=Admins)(cn=Devs))
#ldap.java.naming.provider.url=ldap://192.168.56.106:389
#ldap.java.naming.security.authentication=simple
#ldap.java.naming.security.principal=cn=Manager,dc=timegate,dc=com
#ldap.java.naming.security.credentials=secret
#ldap.user.search.scope=2
#ldap.user.name.attribute=uid
#ldap.user.object.class=inetOrgPerson
#ldap.user.search.base=ou=People,dc=timegate,dc=com

confluent.metadata.server.advertised.listeners=http://{{cp1_broker1_a_public_ip}}:8090
confluent.metadata.server.listeners=http://0.0.0.0:8090
confluent.metadata.server.token.key.path=/var/ssl/private/tokenKeypair.pem
confluent.metadata.server.authentication.method=BEARER
confluent.metadata.server.user.store=FILE 
confluent.metadata.server.user.store.file.path=/var/ssl/private/mdsuser.txt
confluent.metadata.topic.replication.factor=3
confluent.metadata.enable.server.urls.refresh=false

confluent.security.event.logger.destination.admin.bootstrap.servers={{cp1_broker1_a_public_ip}}:9092,{{cp1_broker2_a_public_ip}}:9092,{{cp1_broker3_a_public_ip}}:9092
confluent.security.event.logger.destination.admin.security.protocol=SASL_PLAINTEXT
confluent.security.event.logger.destination.admin.sasl.mechanism=SCRAM-SHA-512
confluent.security.event.logger.destination.admin.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="admin-secret";

confluent.security.event.logger.enable=true
confluent.security.event.logger.exporter.kafka.topic.create=false
confluent.security.event.logger.exporter.kafka.bootstrap.servers={{cp1_broker1_a_public_ip}}:9092,{{cp1_broker2_a_public_ip}}:9092,{{cp1_broker3_a_public_ip}}:9092
confluent.security.event.logger.exporter.kafka.security.protocol=SASL_PLAINTEXT
confluent.security.event.logger.exporter.kafka.sasl.mechanism=SCRAM-SHA-512
confluent.security.event.logger.exporter.kafka.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="admin-secret";

# metric.reporters=io.confluent.telemetry.reporter.TelemetryReporter
# confluent.telemetry.exporter._c3.type=http
# confluent.telemetry.exporter._c3.enabled=true
# confluent.telemetry.exporter._c3.metrics.include=io.confluent.kafka.server.request.(?!.*delta).*|io.confluent.kafka.server.server.broker.state|io.confluent.kafka.server.replica.manager.leader.count|io.confluent.kafka.server.request.queue.size|io.confluent.kafka.server.broker.topic.failed.produce.requests.rate.1.min|io.confluent.kafka.server.tier.archiver.total.lag|io.confluent.kafka.server.request.total.time.ms.p99|io.confluent.kafka.server.broker.topic.failed.fetch.requests.rate.1.min|io.confluent.kafka.server.broker.topic.total.fetch.requests.rate.1.min|io.confluent.kafka.server.partition.caught.up.replicas.count|io.confluent.kafka.server.partition.observer.replicas.count|io.confluent.kafka.server.tier.tasks.num.partitions.in.error|io.confluent.kafka.server.broker.topic.bytes.out.rate.1.min|io.confluent.kafka.server.request.total.time.ms.p95|io.confluent.kafka.server.controller.active.controller.count|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.total|io.confluent.kafka.server.request.total.time.ms.p999|io.confluent.kafka.server.controller.active.broker.count|io.confluent.kafka.server.request.handler.pool.request.handler.avg.idle.percent.rate.1.min|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.rate.1.min|io.confluent.kafka.server.controller.unclean.leader.elections.rate.1.min|io.confluent.kafka.server.replica.manager.partition.count|io.confluent.kafka.server.controller.unclean.leader.elections.total|io.confluent.kafka.server.partition.replicas.count|io.confluent.kafka.server.broker.topic.total.produce.requests.rate.1.min|io.confluent.kafka.server.controller.offline.partitions.count|io.confluent.kafka.server.socket.server.network.processor.avg.idle.percent|io.confluent.kafka.server.partition.under.replicated|io.confluent.kafka.server.log.log.start.offset|io.confluent.kafka.server.log.tier.size|io.confluent.kafka.server.log.size|io.confluent.kafka.server.tier.fetcher.bytes.fetched.total|io.confluent.kafka.server.request.total.time.ms.p50|io.confluent.kafka.server.tenant.consumer.lag.offsets|io.confluent.kafka.server.session.expire.listener.zookeeper.expires.rate.1.min|io.confluent.kafka.server.log.log.end.offset|io.confluent.kafka.server.broker.topic.bytes.in.rate.1.min|io.confluent.kafka.server.partition.under.min.isr|io.confluent.kafka.server.partition.in.sync.replicas.count|io.confluent.telemetry.http.exporter.batches.dropped|io.confluent.telemetry.http.exporter.items.total|io.confluent.telemetry.http.exporter.items.succeeded|io.confluent.telemetry.http.exporter.send.time.total.millis|io.confluent.kafka.server.controller.leader.election.rate.(?!.*delta).*|io.confluent.telemetry.http.exporter.batches.failed
# confluent.telemetry.exporter._c3.client.base.url={{cp1_c3_a_private_ip}}:9090/api/v1/otlp
# confluent.telemetry.exporter._c3.client.compression=gzip
# confluent.telemetry.exporter._c3.api.key=dummy
# confluent.telemetry.exporter._c3.api.secret=dummy
# confluent.telemetry.exporter._c3.buffer.pending.batches.max=80
# confluent.telemetry.exporter._c3.buffer.batch.items.max=4000
# confluent.telemetry.exporter._c3.buffer.inflight.submissions.max=10
# confluent.telemetry.metrics.collector.interval.ms=60000
# confluent.telemetry.remoteconfig._confluent.enabled=false
# confluent.consumer.lag.emitter.enabled=true
